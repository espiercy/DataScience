{
 "metadata": {
  "name": "",
  "signature": "sha256:ed5b1149c3bbe8d1d72fe9c5c99ef9aa2f50674b4bba91cf42ca85127ceee58d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import fetch_20newsgroups\n",
      "categories = ['rec.sport.baseball']\n",
      "dataset = fetch_20newsgroups(subset='all',shuffle=True, random_state=42, categories=categories)\n",
      "corpus = dataset.data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:sklearn.datasets.twenty_newsgroups:Downloading dataset from http://people.csail.mit.edu/jrennie/20Newsgroups/20news-bydate.tar.gz (14 MB)\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "from nltk.corpus import stopwords\n",
      "nltk.download('stopwords')\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.decomposition import TruncatedSVD"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[nltk_data] Downloading package stopwords to\n",
        "[nltk_data]     C:\\Users\\Evan\\AppData\\Roaming\\nltk_data...\n",
        "[nltk_data]   Package stopwords is already up-to-date!\n"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stopset = set(stopwords.words('english'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 62,
       "text": [
        "u\"From: writingctr@leo.bsuvc.bsu.edu\\nSubject: Re: CUB fever.\\nOrganization: Ball State University, Muncie, In - Univ. Computing Svc's\\nLines: 21\\n\\n\\nIn article <kingoz.735285670@camelot>, kingoz@camelot.bradley.edu (Orin Roth) writes:\\n> \\n>    CUB fever is hitting me again. I'm beginning to think they have a \\n>    chance this year. (what the heck am i thinking?)\\n>    Sorry. Just a moment of incompetence.\\n>    I'll be ok. Really. \\n>    Orin.\\n>    Bradley U.\\n> \\n> --\\n> I'm really a jester in disguise!                                   \\nI hear ya!  Then again, we must remember that we are indeed Cub fans, and\\nthat the Cubs will eventually blow it.  After all, the Cubs are the easiest\\nteam in the National League to root for.  No Pressure.  You know they will\\nlose eventually.  Oh well, I suppose we must have faith.  After all, they\\ndo look pretty good, and they don't even have Sandberg back yet.  \\n\\nCUBS IN '93!!!!!\\n\\nCHA\\n\""
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer = TfidfVectorizer(stop_words=stopset, use_idf=True, ngram_range = (1, 3))\n",
      "X = vectorizer.fit_transform(corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 71,
       "text": [
        "<1x191748 sparse matrix of type '<type 'numpy.float64'>'\n",
        "\twith 238 stored elements in Compressed Sparse Row format>"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  (0, 52228)\t0.0731439323579\n",
        "  (0, 191020)\t0.0731439323579\n",
        "  (0, 29689)\t0.0731439323579\n",
        "  (0, 147835)\t0.0731439323579\n",
        "  (0, 65182)\t0.0731439323579\n",
        "  (0, 78888)\t0.0731439323579\n",
        "  (0, 134450)\t0.0731439323579\n",
        "  (0, 104481)\t0.0731439323579\n",
        "  (0, 67566)\t0.0731439323579\n",
        "  (0, 115566)\t0.0731439323579\n",
        "  (0, 164657)\t0.0731439323579\n",
        "  (0, 182643)\t0.0731439323579\n",
        "  (0, 120918)\t0.0731439323579\n",
        "  (0, 65316)\t0.0731439323579\n",
        "  (0, 104975)\t0.0731439323579\n",
        "  (0, 96499)\t0.0731439323579\n",
        "  (0, 134365)\t0.0731439323579\n",
        "  (0, 145006)\t0.0731439323579\n",
        "  (0, 99096)\t0.0731439323579\n",
        "  (0, 116208)\t0.0731439323579\n",
        "  (0, 167016)\t0.0731439323579\n",
        "  (0, 60429)\t0.0731439323579\n",
        "  (0, 52268)\t0.0731439323579\n",
        "  (0, 36453)\t0.0731439323579\n",
        "  (0, 65306)\t0.0731439323579\n",
        "  :\t:\n",
        "  (0, 123582)\t0.109931779998\n",
        "  (0, 38249)\t0.0985767742926\n",
        "  (0, 41418)\t0.104094504416\n",
        "  (0, 17244)\t0.0731439323579\n",
        "  (0, 95910)\t0.109931779998\n",
        "  (0, 26511)\t0.01601326942\n",
        "  (0, 7904)\t0.037367740246\n",
        "  (0, 101906)\t0.0102067218536\n",
        "  (0, 165246)\t0.0604342027887\n",
        "  (0, 48913)\t0.0386375652161\n",
        "  (0, 176779)\t0.0389815086153\n",
        "  (0, 115364)\t0.0604342027887\n",
        "  (0, 176815)\t0.0178629869961\n",
        "  (0, 160345)\t0.0370736512892\n",
        "  (0, 30211)\t0.0304858178875\n",
        "  (0, 122967)\t0.0102272590238\n",
        "  (0, 69119)\t0.123996233431\n",
        "  (0, 52150)\t0.160205928216\n",
        "  (0, 138484)\t0.012615234167\n",
        "  (0, 163223)\t0.0101453586104\n",
        "  (0, 60929)\t0.02363037129\n",
        "  (0, 39489)\t0.0503037697243\n",
        "  (0, 39499)\t0.0503037697243\n",
        "  (0, 100110)\t0.0492883871463\n",
        "  (0, 188519)\t0.0731439323579\n"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok. That took a long time for not very much code. Special thanks to all the relevant posts in the discussion board!\n",
      "\n",
      "###Time For The LSA"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 73,
       "text": [
        "(994, 191748)"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsa = TruncatedSVD(n_components=10, n_iter=100)\n",
      "lsa.fit(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 80,
       "text": [
        "TruncatedSVD(algorithm='randomized', n_components=10, n_iter=100,\n",
        "       random_state=None, tol=0.0)"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I'm going to go ahead and look at the first 10 components."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsa.components_[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 79,
       "text": [
        "array([ 0.01618776,  0.00505051,  0.00083803, ...,  0.00103122,\n",
        "        0.00103122,  0.00103122])"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "terms = vectorizer.get_feature_names()\n",
      "for i, comp in enumerate(lsa.components_):\n",
      "    termsInComp = zip (terms, comp)\n",
      "    sortedTerms = sorted(termsInComp, key=lambda x: x[1], reverse = True) [:10]\n",
      "    print \"Concept %d:\" % i\n",
      "    for term in sortedTerms:\n",
      "        print term[0]\n",
      "    print\" \""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Concept 0:\n",
        "edu\n",
        "com\n",
        "year\n",
        "writes\n",
        "team\n",
        "would\n",
        "game\n",
        "article\n",
        "re\n",
        "cs\n",
        " \n",
        "Concept 1:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "time\n",
        "00 00 00\n",
        "subject re\n",
        "posting\n",
        "anyone\n",
        "season\n",
        "sox\n",
        "much\n",
        "league\n",
        "really\n",
        " \n",
        "Concept 2:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "com\n",
        "win\n",
        "organization\n",
        "would\n",
        "time\n",
        "years\n",
        "organization university\n",
        "morris\n",
        "00 00 baltimore\n",
        "players\n",
        " \n",
        "Concept 3:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "00\n",
        "00 00\n",
        "00 00 00\n",
        "game\n",
        "would\n",
        "good\n",
        "know\n",
        "bonds\n",
        "like\n",
        "look\n",
        " \n",
        "Concept 4:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "00\n",
        "00 00\n",
        "baseball\n",
        "year\n",
        "team\n",
        "nntp\n",
        "00 00 000\n",
        "nntp posting\n",
        "subject re\n",
        "get\n",
        " \n",
        "Concept 5:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "year\n",
        "subject re\n",
        "good\n",
        "may\n",
        "first\n",
        "get\n",
        "well\n",
        "last\n",
        "posting\n",
        "edu organization\n",
        " \n",
        "Concept 6:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "writes\n",
        "subject\n",
        "would\n",
        "team\n",
        "could\n",
        "year\n",
        "00 00 gmt\n",
        "hitter\n",
        "players\n",
        "edu\n",
        " \n",
        "Concept 7:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "re\n",
        "cs\n",
        "hit\n",
        "article\n",
        "00 00 colorado\n",
        "university\n",
        "league\n",
        "00 00 chicago\n",
        "better\n",
        "come\n",
        " \n",
        "Concept 8:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "00 00 01\n",
        "lines\n",
        "00 00 colorado\n",
        "would\n",
        "com\n",
        "last\n",
        "writes article\n",
        "edu\n",
        "first\n",
        "team\n",
        " \n",
        "Concept 9:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "baseball\n",
        "com\n",
        "university\n",
        "re\n",
        "posting\n",
        "00 00 colorado\n",
        "first\n",
        "many\n",
        "subject re\n",
        "like\n",
        " \n"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At first glance I can't make any inferences about these posts, aside from the fact that they are about baseball. It's also not a very good sign that words like \"article\" or \"com\" pop up frequently, nor words like \"much\" and \"really,\" which ironically never lend anything to a well-written piece, so I'd better try to clean up the list of strings I'm dropping from the analysis and try the whole shebang all over again. As it stands, the vast majority of these words are worthless."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stopset.update(['edu', 'com' , 'writes' , 'would', 'article', 'cs', '00 00 00', 'subject re', 'posting', 'anyone', 'much', 'would', \"00\", \"00 00\", \"good\" , \"know\", \"like\", \"look\",\n",
      "                'nntp', '00 00 000', 'nntp posting', 'subject re', 'get', 'good','well', 'last', 'lines', 'writes article', 'many','like',\n",
      "                're', 'think', 'subject', 'year', 'two', '000 000 067', '000 000 assuming', '000 000 151', 'could', 'game', 'baseball', '000 000 next',\n",
      "                '000 000 74', 'great', '12', '11', 'team', 'one', '000 000 next', '000 000 assuming', 'games', 'players', 'us', 'reply',\n",
      "                'first', 'also', 'better', 'doesn', 'netcom', 'might', 'distribution na', 'really', 'let', 'didn'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer = TfidfVectorizer(stop_words=stopset, use_idf=True, ngram_range = (1, 3))\n",
      "X = vectorizer.fit_transform(corpus)\n",
      "lsa = TruncatedSVD(n_components=10, n_iter=100)\n",
      "lsa.fit(X)\n",
      "terms = vectorizer.get_feature_names()\n",
      "for i, comp in enumerate(lsa.components_):\n",
      "    termsInComp = zip (terms, comp)\n",
      "    sortedTerms = sorted(termsInComp, key=lambda x: x[1], reverse = True) [:10]\n",
      "    print \"Concept %d:\" % i\n",
      "    for term in sortedTerms:\n",
      "        print term[0]\n",
      "    print\" \""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Concept 0:\n",
        "morris\n",
        "organization\n",
        "hit\n",
        "runs\n",
        "time\n",
        "jewish\n",
        "university\n",
        "roger\n",
        "win\n",
        "braves\n",
        " \n",
        "Concept 1:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "jewish\n",
        "lafayette\n",
        "lafibm\n",
        "vb30\n",
        "lafayette vb30\n",
        "lafibm lafayette\n",
        "lafibm lafayette vb30\n",
        "hit\n",
        "mets\n",
        "000 000\n",
        " \n",
        "Concept 2:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "000 000 74\n",
        "say\n",
        "runs\n",
        "morris\n",
        "maybe\n",
        "base\n",
        "organization\n",
        "000 000 assuming\n",
        "15\n",
        "000 006\n",
        " \n",
        "Concept 3:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "gant\n",
        "braves\n",
        "back\n",
        "organization\n",
        "host\n",
        "hirschbeck\n",
        "bonds\n",
        "go\n",
        "say\n",
        "something\n",
        " \n",
        "Concept 4:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "host\n",
        "morris\n",
        "right\n",
        "runs\n",
        "time\n",
        "000 000 kasai\n",
        "university\n",
        "ball\n",
        "000 000 74\n",
        "braves\n",
        " \n",
        "Concept 5:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "000 000 74\n",
        "organization\n",
        "000 000 assuming\n",
        "run\n",
        "000 006\n",
        "ll\n",
        "back\n",
        "university\n",
        "right\n",
        "000 000 067\n",
        " \n",
        "Concept 6:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "ll\n",
        "batting\n",
        "right\n",
        "organization university\n",
        "years\n",
        "world\n",
        "division\n",
        "league\n",
        "average\n",
        "going\n",
        " \n",
        "Concept 7:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "organization\n",
        "mets\n",
        "hit\n",
        "000 000 74\n",
        "pitching\n",
        "time\n",
        "see\n",
        "000 006\n",
        "alomar\n",
        "make\n",
        " \n",
        "Concept 8:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "won\n",
        "say\n",
        "time\n",
        "play\n",
        "host\n",
        "player\n",
        "mets\n",
        "may\n",
        "strike\n",
        "least\n",
        " \n",
        "Concept 9:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "ca\n",
        "braves\n",
        "best\n",
        "won\n",
        "ll\n",
        "000 000 assuming\n",
        "win\n",
        "guys\n",
        "000 006\n",
        "big\n",
        " \n"
       ]
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I'm constantly updating the list of words I need to throw out, so rather than redo my work, I'm updating everything above.\n",
      "\n",
      "Oh, great. The stopper isn't stopping things I'm telling it to, like 000 000 74. Awesome. Now what? Perusing the blackboard, it doesn't look like the assignment requires me to actually strip the text, but I'll be, that really does get in the way of trying to take concepts out of these posts. Not knowing anything about baseball sure doesn't help.\n",
      "\n",
      "It doesn't look like any amount of sequences I add to the stop list is actually going to help me come up with concepts that are more than anything but really, really fuzzy.\n",
      "\n",
      "These posts are generally talking about games, aspects of games like pitching, big game regions (ny, ca), teams (braves, mets), wins/losses, specific players, game events like strikes, and who won. University also comes up quite a bit so it's safe to assume that college baseball gets discussed pretty frequently. Concept 1 mentions lafayette a lot, so that has to be important.\n",
      "\n",
      "I would like to take a closer look at the emotive content in these postings, but words like \"good,\"\"great,\" etc. really gum up the works. Still, speaking with absolutely no prior knowledge, this looks like a list of words someone would look at and say \"hey! Those are about baseball!\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}