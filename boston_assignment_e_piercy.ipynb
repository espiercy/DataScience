{
 "metadata": {
  "name": "",
  "signature": "sha256:5cee62c00a5da6eb07414b086aca75335e41d6a4d51decca6488cb71fcfe74a3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Boston Housing Assignment\n",
      "\n",
      "In this assignment you'll be using linear regression to estimate the cost of house in boston, using a well known dataset.\n",
      "\n",
      "Goals:\n",
      "+  Measure the performance of the model I created using $R^{2}$ and MSE\n",
      "> Learn how to use sklearn.metrics.r2_score and sklearn.metrics.mean_squared_error\n",
      "+  Implement a new model using L2 regularization\n",
      "> Use sklearn.linear_model.Ridge or sklearn.linear_model.Lasso \n",
      "+  Get the best model you can by optimizing the regularization parameter.   "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import datasets\n",
      "import pandas as pd\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.metrics import mean_squared_error\n",
      "from sklearn.metrics import r2_score\n",
      "from sklearn.linear_model import LinearRegression"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bean = datasets.load_boston()\n",
      "print bean.DESCR"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Boston House Prices dataset\n",
        "\n",
        "Notes\n",
        "------\n",
        "Data Set Characteristics:  \n",
        "\n",
        "    :Number of Instances: 506 \n",
        "\n",
        "    :Number of Attributes: 13 numeric/categorical predictive\n",
        "    \n",
        "    :Median Value (attribute 14) is usually the target\n",
        "\n",
        "    :Attribute Information (in order):\n",
        "        - CRIM     per capita crime rate by town\n",
        "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
        "        - INDUS    proportion of non-retail business acres per town\n",
        "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
        "        - NOX      nitric oxides concentration (parts per 10 million)\n",
        "        - RM       average number of rooms per dwelling\n",
        "        - AGE      proportion of owner-occupied units built prior to 1940\n",
        "        - DIS      weighted distances to five Boston employment centres\n",
        "        - RAD      index of accessibility to radial highways\n",
        "        - TAX      full-value property-tax rate per $10,000\n",
        "        - PTRATIO  pupil-teacher ratio by town\n",
        "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
        "        - LSTAT    % lower status of the population\n",
        "        - MEDV     Median value of owner-occupied homes in $1000's\n",
        "\n",
        "    :Missing Attribute Values: None\n",
        "\n",
        "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
        "\n",
        "This is a copy of UCI ML housing dataset.\n",
        "http://archive.ics.uci.edu/ml/datasets/Housing\n",
        "\n",
        "\n",
        "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
        "\n",
        "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
        "prices and the demand for clean air', J. Environ. Economics & Management,\n",
        "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
        "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
        "pages 244-261 of the latter.\n",
        "\n",
        "The Boston house-price data has been used in many machine learning papers that address regression\n",
        "problems.   \n",
        "     \n",
        "**References**\n",
        "\n",
        "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
        "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
        "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_boston():\n",
      "    scaler = StandardScaler()\n",
      "    boston = datasets.load_boston()\n",
      "    X=boston.data\n",
      "    y=boston.target\n",
      "    X = scaler.fit_transform(X)\n",
      "    return train_test_split(X,y)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = load_boston()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "(379L, 13L)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Fitting a Linear Regression\n",
      "\n",
      "It's as easy as instantiating a new regression object (line 1) and giving your regression object your training data\n",
      "(line 2) by calling .fit(independent variables, dependent variable)\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "clf = LinearRegression()\n",
      "clf.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "LinearRegression(copy_X=True, fit_intercept=True, normalize=False)"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Making a Prediction\n",
      "X_test is our holdout set of data.  We know the answer (y_test) but the computer does not.   \n",
      "\n",
      "Using the command below, I create a tuple for each observation, where I'm combining the real value (y_test) with\n",
      "the value our regressor predicts (clf.predict(X_test))\n",
      "\n",
      "Use a similiar format to get your r2 and mse metrics working.  Using the [scikit learn api](http://scikit-learn.org/stable/modules/model_evaluation.html) if you need help!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "zip (y_test, clf.predict(X_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "[(21.0, 22.632628902561343),\n",
        " (21.800000000000001, 19.973394509331897),\n",
        " (16.399999999999999, 18.58099725704173),\n",
        " (20.699999999999999, 25.125631564070943),\n",
        " (36.399999999999999, 32.668171589037485),\n",
        " (19.399999999999999, 17.757835899518128),\n",
        " (46.700000000000003, 35.31693137250091),\n",
        " (22.600000000000001, 26.930358781890579),\n",
        " (19.300000000000001, 20.503082274578759),\n",
        " (29.800000000000001, 25.223673049214042),\n",
        " (32.5, 30.793238681127882),\n",
        " (20.899999999999999, 20.684586454454397),\n",
        " (12.5, 19.019443542353976),\n",
        " (31.0, 34.569756265177247),\n",
        " (21.899999999999999, 23.639921654426445),\n",
        " (17.800000000000001, 17.995258165741259),\n",
        " (24.0, 29.675650000006463),\n",
        " (16.100000000000001, 20.702485536071972),\n",
        " (13.199999999999999, 9.209159432550269),\n",
        " (28.699999999999999, 25.233196904779863),\n",
        " (23.899999999999999, 24.871017051022953),\n",
        " (19.800000000000001, 22.436623546373646),\n",
        " (24.5, 20.08390675067373),\n",
        " (23.600000000000001, 28.921581912168129),\n",
        " (23.800000000000001, 24.717867726409043),\n",
        " (26.600000000000001, 27.785923052593464),\n",
        " (36.0, 36.405698741462551),\n",
        " (15.6, 13.208518766733594),\n",
        " (22.399999999999999, 22.459481739940259),\n",
        " (5.0, 9.6261737599100048),\n",
        " (27.0, 32.289632780650017),\n",
        " (29.0, 31.595747516023149),\n",
        " (20.300000000000001, 23.100381418857861),\n",
        " (27.899999999999999, 19.139560167525943),\n",
        " (17.899999999999999, 1.6193565510576207),\n",
        " (13.4, 13.112510591774468),\n",
        " (13.1, 13.016975706316771),\n",
        " (14.5, 14.033529037740724),\n",
        " (29.100000000000001, 29.854760969010691),\n",
        " (22.399999999999999, 23.327454400266401),\n",
        " (29.899999999999999, 31.339562581245609),\n",
        " (23.199999999999999, 25.348060148355941),\n",
        " (22.699999999999999, 25.201389068138692),\n",
        " (14.800000000000001, 14.778308316589644),\n",
        " (12.300000000000001, 12.758248522545987),\n",
        " (20.600000000000001, 18.818444093359268),\n",
        " (13.800000000000001, 19.727450960709561),\n",
        " (33.399999999999999, 35.142490756879681),\n",
        " (50.0, 37.925674866208269),\n",
        " (23.399999999999999, 24.061883418892862),\n",
        " (23.0, 23.448833897462123),\n",
        " (24.100000000000001, 25.364358145574876),\n",
        " (21.5, 25.048379431767632),\n",
        " (34.899999999999999, 29.236752883434761),\n",
        " (15.6, 15.774128187006212),\n",
        " (31.600000000000001, 32.522774982019087),\n",
        " (27.5, 31.779394722351871),\n",
        " (5.5999999999999996, 12.39579076352603),\n",
        " (23.300000000000001, 26.354236608369902),\n",
        " (35.399999999999999, 30.670404872492689),\n",
        " (21.899999999999999, 14.198735856987073),\n",
        " (33.200000000000003, 35.035836439764019),\n",
        " (18.199999999999999, 13.348513415433164),\n",
        " (23.199999999999999, 16.8146502809414),\n",
        " (24.300000000000001, 24.345874717777583),\n",
        " (11.0, 13.648975838425974),\n",
        " (6.2999999999999998, 10.896212485399015),\n",
        " (26.399999999999999, 22.570934706030485),\n",
        " (23.0, 29.653280558865255),\n",
        " (15.699999999999999, 15.742174007828069),\n",
        " (17.199999999999999, 16.823532665049139),\n",
        " (13.800000000000001, 16.002816765438677),\n",
        " (31.699999999999999, 33.398678067609183),\n",
        " (36.5, 35.697321997028055),\n",
        " (17.100000000000001, 17.092183379497246),\n",
        " (25.300000000000001, 25.135631148414046),\n",
        " (23.100000000000001, 24.636924517124182),\n",
        " (13.6, 12.650051414019909),\n",
        " (22.300000000000001, 27.17174379241834),\n",
        " (28.699999999999999, 28.833469855196039),\n",
        " (43.5, 39.151585306222799),\n",
        " (24.699999999999999, 22.49496661637281),\n",
        " (19.600000000000001, 22.744430529860473),\n",
        " (22.100000000000001, 26.397166182571315),\n",
        " (34.899999999999999, 33.188021548931161),\n",
        " (42.299999999999997, 36.606050583379549),\n",
        " (15.6, 12.594746798636482),\n",
        " (27.5, 12.07830638683031),\n",
        " (14.9, 17.170953171737764),\n",
        " (32.0, 32.896021272784388),\n",
        " (30.300000000000001, 32.70872436068619),\n",
        " (19.800000000000001, 21.501259425980475),\n",
        " (20.0, 23.297516727542195),\n",
        " (36.200000000000003, 27.430503293960918),\n",
        " (18.899999999999999, 14.620652475453847),\n",
        " (17.199999999999999, 15.173440433483336),\n",
        " (12.0, 11.560506859063697),\n",
        " (14.6, 8.8461948765956233),\n",
        " (10.9, 13.879443102251033),\n",
        " (11.800000000000001, 12.361413763523773),\n",
        " (22.199999999999999, 19.425371134151295),\n",
        " (50.0, 43.985000502035923),\n",
        " (22.600000000000001, 23.996988300249111),\n",
        " (25.0, 22.705860213556761),\n",
        " (25.0, 28.775068752932441),\n",
        " (17.600000000000001, 16.432585948296456),\n",
        " (15.199999999999999, 16.086587369819277),\n",
        " (13.1, 16.297344439934619),\n",
        " (8.3000000000000007, 12.87411375472497),\n",
        " (50.0, 31.230996007819048),\n",
        " (18.199999999999999, 19.077883616892343),\n",
        " (29.100000000000001, 31.100667277649457),\n",
        " (22.899999999999999, 24.693115060628084),\n",
        " (32.399999999999999, 35.044577145240197),\n",
        " (22.300000000000001, 27.085874803407744),\n",
        " (18.800000000000001, 21.337656584512164),\n",
        " (50.0, 24.447074021364486),\n",
        " (22.0, 20.924738776136039),\n",
        " (20.300000000000001, 23.407444411836451),\n",
        " (50.0, 35.98683690489527),\n",
        " (20.600000000000001, 21.75620761078828),\n",
        " (23.100000000000001, 24.311377062496557),\n",
        " (25.0, 24.870211604047491),\n",
        " (19.699999999999999, 13.854355455156854),\n",
        " (17.699999999999999, 19.624198833250276),\n",
        " (50.0, 42.71200101484429),\n",
        " (29.600000000000001, 24.953454599327685)]"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "first_R_2 = r2_score(y_test, clf.predict(X_test))\n",
      "first_R_2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 176,
       "text": [
        "0.70644177455290003"
       ]
      }
     ],
     "prompt_number": 176
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###First R^2 = 0.70644177455290003"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###For MSE"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "first_mse = mean_squared_error(y_test, clf.predict(X_test))\n",
      "first_mse"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "26.755941020337918"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "first_rmse = math.sqrt(first_mse)\n",
      "first_rmse"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "5.172614524622719"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###RMSE = 5.172614524622719"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import Ridge\n",
      "ridge_test = Ridge(alpha = 0.0)\n",
      "ridge_test.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 182,
       "text": [
        "Ridge(alpha=0.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
        "   normalize=False, solver='auto', tol=0.001)"
       ]
      }
     ],
     "prompt_number": 182
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "second_R_2 = r2_score(y_test, ridge_test.predict(X_test))\n",
      "second_R_2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 183,
       "text": [
        "0.70644177455289991"
       ]
      }
     ],
     "prompt_number": 183
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_mse = mean_squared_error(y_test, ridge_test.predict(X_test))\n",
      "print test_mse"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "26.7559410203\n"
       ]
      }
     ],
     "prompt_number": 184
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_rmse = math.sqrt(test_mse)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 185
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print test_rmse"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5.17261452462\n"
       ]
      }
     ],
     "prompt_number": 186
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###If I am using this model correctly, the best alpha value is zero. In this instance, the predictions from both models. I got the best model I could using alpha = 0.0. The higher the alpha value, the (slightly lower) each score was. I'd thought the point of the regularization parameter was to help reduce both the R^2 and the RMSE values, but in this case I guess it didn't make much of a change?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}